{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and move to dataset directory\n",
    "datasetdir = 'F:/Datasets/doggy_dataset'\n",
    "import os\n",
    "os.chdir(datasetdir)\n",
    "\n",
    "#Import the needed packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining two functions that we will need later.\n",
    "\n",
    "#The first function : generators\n",
    "#It returns two image iterators that we will use to produce batches of images for the training and the validation of our neural networks.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 30\n",
    "\n",
    "def generators(shape, preprocessing): \n",
    "    '''Create the training and validation datasets for \n",
    "    a given image shape.\n",
    "    '''\n",
    "    imgdatagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocessing,\n",
    "        horizontal_flip = True, \n",
    "        validation_split = 0.1,\n",
    "    )\n",
    "\n",
    "    height, width = shape\n",
    "\n",
    "    train_dataset = imgdatagen.flow_from_directory(\n",
    "        os.getcwd(),\n",
    "        target_size = (height, width), \n",
    "        classes = ('lying','notlying'),\n",
    "        batch_size = batch_size,\n",
    "        subset = 'training', \n",
    "    )\n",
    "\n",
    "    val_dataset = imgdatagen.flow_from_directory(\n",
    "        os.getcwd(),\n",
    "        target_size = (height, width), \n",
    "        classes = ('lying','notlying'),\n",
    "        batch_size = batch_size,\n",
    "        subset = 'validation'\n",
    "    )\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second function will be used to plot the accuracy and loss as a function of the epoch.\n",
    "#So that we can see how the training worked.\n",
    "def plot_history(history, yrange):\n",
    "    '''Plot loss and accuracy as a function of the epoch,\n",
    "    for the training and validation datasets.\n",
    "    '''\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Get number of epochs\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    # Plot training and validation accuracy per epoch\n",
    "    plt.plot(epochs, acc)\n",
    "    plt.plot(epochs, val_acc)\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.ylim(yrange)\n",
    "    \n",
    "    # Plot training and validation loss per epoch\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.title('Training and validation loss')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4312 images belonging to 2 classes.\n",
      "Found 478 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Build a ResNet50 network with keras.\n",
    "\n",
    "#Step 1 - Create our dataset iterators, with the right input shape and preprocessing functions.\n",
    "resnet50 = keras.applications.resnet50\n",
    "train_dataset, val_dataset = generators((224,224), preprocessing=resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 429s 5us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          10035300    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            202         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 33,643,414\n",
      "Trainable params: 10,055,702\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Step 2 - Create our full model, that is the convolutional part of ResNet50 followed by our simple classifier and train it.\n",
    "conv_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "x = keras.layers.Flatten()(conv_model.output)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(2, activation='softmax')(x)\n",
    "full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-af3e800e6f8d>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 144 steps, validate for 16 steps\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 1057s 7s/step - loss: 0.7424 - acc: 0.7866 - val_loss: 0.5818 - val_acc: 0.7510\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 934s 6s/step - loss: 0.2677 - acc: 0.8933 - val_loss: 1.0723 - val_acc: 0.6862\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 1669s 12s/step - loss: 0.1807 - acc: 0.9330 - val_loss: 0.7715 - val_acc: 0.7197\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 971s 7s/step - loss: 0.1026 - acc: 0.9666 - val_loss: 0.8347 - val_acc: 0.7364\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 1059s 7s/step - loss: 0.0682 - acc: 0.9754 - val_loss: 0.7517 - val_acc: 0.7531\n"
     ]
    }
   ],
   "source": [
    "full_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adamax(lr=0.001),\n",
    "                  metrics=['acc'])\n",
    "history = full_model.fit_generator(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=10,\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, yrange=(0.9,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "full_model.save_weights('resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read them again, we create a new model, identical to the one we have trained\n",
    "conv_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "x = keras.layers.Flatten()(conv_model.output)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(2, activation='softmax')(x)\n",
    "full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And we load the weights\n",
    "full_model.load_weights('resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating batch 143\r"
     ]
    }
   ],
   "source": [
    "#evaluating the model for all images in the training dataset\n",
    "import sys\n",
    "\n",
    "def true_and_predicted_labels(dataset):\n",
    "    labels = np.zeros((dataset.n,2))\n",
    "    preds = np.zeros_like(labels)\n",
    "    for i in range(len(dataset)):\n",
    "        sys.stdout.write('evaluating batch {}\\r'.format(i))\n",
    "        sys.stdout.flush()\n",
    "        batch = dataset[i]\n",
    "        batch_images = batch[0]\n",
    "        batch_labels = batch[1]\n",
    "        batch_preds = full_model.predict(batch_images)\n",
    "        start = i*batch_size\n",
    "        labels[start:start+batch_size] = batch_labels\n",
    "        preds[start:start+batch_size] = batch_preds\n",
    "    return labels, preds\n",
    "\n",
    "train_labels, train_preds = true_and_predicted_labels(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Illustrate how the model is able to separate the two categories : lying = 1 and notlying = 0\n",
    "#Plot the lying score for the two categories :\n",
    "#For lying, we expect the lying score to be close to one. For notlying, it will be close to zero.\n",
    "def plot_lying_score(preds, labels, range=(0,1)):\n",
    "    # get the lying score for all images\n",
    "    lying_score = preds[:,1]\n",
    "    # get the lying score for notlying\n",
    "    # we use the true labels to select notlying images\n",
    "    notlying_lying_score = lying_score[labels[:,0]>0.5]\n",
    "    # and for lying\n",
    "    lying_lying_score = lying_score[labels[:,0]<0.5]\n",
    "    # just some plotting parameters\n",
    "    params = {'bins':100, 'range':range, 'alpha':0.6}\n",
    "    plt.hist(notlying_lying_score, **params)\n",
    "    plt.hist(lying_lying_score, **params)\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_lying_score(train_preds, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels:\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "true labels:\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Compute accuracy\n",
    "\n",
    "#Using lying score, we need to compute the predicted labels and compare them with the true labels.\n",
    "#We decide that the network predicts lying if the lying score is larger than a given threshold.\n",
    "#Keras provides an estimation of the accuraccy during the training.\n",
    "#For this estimation, keras uses a threshold of 0.5\n",
    "threshold = 0.5\n",
    "\n",
    "def predicted_labels(preds, threshold):\n",
    "    '''Turn predictions (floats in the last two dimensions) \n",
    "    into labels (0 or 1).'''\n",
    "    pred_labels = np.zeros_like(preds)\n",
    "    # lying score lower than threshold: set notlying label to 1\n",
    "    # lying score higher than threshold: set notlying label to 0\n",
    "    pred_labels[:,0] = preds[:,1]<threshold\n",
    "    # lying score higher than threshold: set lying label to 1\n",
    "    # lying score lower than threshold: set lying label to 0\n",
    "    pred_labels[:,1] = preds[:,1]>=threshold\n",
    "    return pred_labels\n",
    "\n",
    "train_pred_labels = predicted_labels(train_preds, threshold)\n",
    "print('predicted labels:')\n",
    "print(train_pred_labels)\n",
    "print('true labels:')\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all  126 misclassified samples (97.08%)\n",
      "lying  81 misclassified samples (95.02%)\n",
      "notlying  45 misclassified samples (98.32%)\n"
     ]
    }
   ],
   "source": [
    "#It seems that the predicted labels are very similar to the true labels.\n",
    "#This is because the accuracy is close to 100%, and only a few examples are shown in the printout above.\n",
    "#Let's quantify the fraction of misclassified examples:\n",
    "def misclassified(labels, pred_labels, print_report=True):\n",
    "    def report(categ, n_misclassified, n_examples): \n",
    "        print('{:<4} {:>3} misclassified samples ({:4.2f}%)'.format(\n",
    "            categ,\n",
    "            n_misclassified, \n",
    "            100*(1-float(n_misclassified)/n_examples))\n",
    "        )\n",
    "    # total number of examples\n",
    "    n_examples = len(labels)\n",
    "    # total number of lying\n",
    "    n_lying = sum(labels[:,0])\n",
    "    # total number of notlying\n",
    "    n_notlying = sum(labels[:,1])\n",
    "    # boolean mask for misidentified examples\n",
    "    mask_all = pred_labels[:,0] != labels[:,0]\n",
    "    # boolean mask for misidentified lying    \n",
    "    mask_lying = np.logical_and(mask_all,labels[:,1]>0.5)\n",
    "    # boolean mask for misidentified notlying    \n",
    "    mask_notlying = np.logical_and(mask_all,labels[:,1]<0.5)\n",
    "    if print_report:\n",
    "        report('all', sum(mask_all), n_examples)\n",
    "        report('lying', sum(mask_lying), n_lying)\n",
    "        report('notlying', sum(mask_notlying), n_notlying)\n",
    "    return mask_all, mask_lying, mask_notlying\n",
    "\n",
    "_ = misclassified(train_labels, train_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all  114 misclassified samples (76.15%)\n",
      "lying  35 misclassified samples (80.56%)\n",
      "notlying  79 misclassified samples (73.49%)\n"
     ]
    }
   ],
   "source": [
    "#Validation dataset\n",
    "val_labels, val_preds = true_and_predicted_labels(val_dataset)\n",
    "val_pred_labels = predicted_labels(val_preds, threshold)\n",
    "_ = misclassified(val_labels, val_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
