{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#step 1 - read the video, extract frames from it and save them as images\n",
    "\n",
    "count = 0\n",
    "videoFile = \"F:/Datasets/doggy_dataset/testvideos/testdog3video1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"frame%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_ID  Class\n",
       "0  frame0.jpg      0\n",
       "1  frame1.jpg      0\n",
       "2  frame2.jpg      0\n",
       "3  frame3.jpg      0\n",
       "4  frame4.jpg      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 2 - Label a few images for training the model\n",
    "\n",
    "#label 0 - nodog, label 1 - lyingdog, label 2 - notlyingdog\n",
    "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
    "data.head()      # printing first five rows of the file\n",
    "#the mapping file contains two columns as Image_ID (Contains the name of each image) and Class (Contains corresponding class for each image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read images based on their names(Image_ID)\n",
    "X = []\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    X.append(img)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there are three classes, i will one hot encode them using the to_categorical() function of keras.utils\n",
    "from keras.utils import np_utils\n",
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)    # one hot encoding Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 pretrained model is used to build the model and it takes an input image of shape (224 X 224 X 3)\n",
    "#since the images are in a different size, it is necessary to reshape all of them\n",
    "#resize() function of skimage.transform is used to do this\n",
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make the model performe well, it requires to preprocess all the inputs before passing them to the model\n",
    "#preprocess_input() function of keras.applications.resnet50 is used to do this\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "X = preprocess_input(X, mode='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a validation set is used to check the performance of the model on unseen images\n",
    "#train_test_split() function of the sklearn.model_selection module is used to randomly divide images into training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 - building the model\n",
    "\n",
    "#import required libraries to build the model\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pradeepika\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "#load the ResNet50 pretrained model and store it as base_model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 7, 7, 2048), (36, 7, 7, 2048))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make predictions using this model for X_train and X_valid, get the features, and then use those features to retrain the model\n",
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the shape of X_train and X_valid is (82, 7, 7, 2048), (36, 7, 7, 2048) respectively\n",
    "#in order to pass it to neural network, it needs to reshape to 1-D\n",
    "X_train = X_train.reshape(82, 7*7*2048)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(36, 7*7*2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the images and make them zero-centered which helps the model to converge faster\n",
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.1 - building the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*2048,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(3, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 102,764,547\n",
      "Trainable params: 102,764,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.2 - compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82 samples, validate on 36 samples\n",
      "Epoch 1/10\n",
      "82/82 [==============================] - 379s 5s/step - loss: 1.1829 - accuracy: 0.3780 - val_loss: 0.5839 - val_accuracy: 0.7222\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 458s 6s/step - loss: 0.5994 - accuracy: 0.7805 - val_loss: 0.4406 - val_accuracy: 0.9167\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 509s 6s/step - loss: 0.4110 - accuracy: 0.8293 - val_loss: 0.3302 - val_accuracy: 0.8611\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 603s 7s/step - loss: 0.2982 - accuracy: 0.9634 - val_loss: 0.2900 - val_accuracy: 0.9444\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 263s 3s/step - loss: 0.2582 - accuracy: 0.9634 - val_loss: 0.2483 - val_accuracy: 0.9722\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 310s 4s/step - loss: 0.2135 - accuracy: 0.9512 - val_loss: 0.2058 - val_accuracy: 0.9444\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 404s 5s/step - loss: 0.1713 - accuracy: 0.9634 - val_loss: 0.1757 - val_accuracy: 0.9444\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 117s 1s/step - loss: 0.1463 - accuracy: 0.9634 - val_loss: 0.1706 - val_accuracy: 0.9722\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1372 - accuracy: 0.9512 - val_loss: 0.1612 - val_accuracy: 0.9722\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 146s 2s/step - loss: 0.1195 - accuracy: 0.9878 - val_loss: 0.1408 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25a28635d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3.3 - training the model\n",
    "model.fit(train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#training with a new video\n",
    "#load the new video and extract frames from it\n",
    "count = 0\n",
    "videoFile = \"F:/Datasets/doggy_dataset/testvideos/testdog2video2.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the testing.csv file which contains the names of each extracted frame\n",
    "test = pd.read_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the images for testing and then reshape them as per the requirements of the aforementioned pretrained model\n",
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np_utils.to_categorical(test.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224,3)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now it needs to make changes to test images similar to the ones we did for the training images\n",
    "\n",
    "#preprocessing the images\n",
    "test_image = preprocess_input(test_image, mode='tf')\n",
    "#test_image.shape\n",
    "\n",
    "#extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "\n",
    "#converting the images to 1-D form\n",
    "test_image = test_image.reshape(62, 7, 7, 2048)\n",
    "\n",
    "#zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 - make predictions for the remaining images\n",
    "\n",
    "predictions = model.predict_classes(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resting time of the dog = 60 seconds\n"
     ]
    }
   ],
   "source": [
    "#step 5 - calculate resting time of the dog\n",
    "print(\"Resting time of the dog = \", predictions[predictions==1].shape[0], \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('dogresting.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
